---
title: "Scratch"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Setup

```{r}
library(tidyverse)
library(pins)
library(dtplyr)
library(dplyr, warn.conflicts = FALSE)

# Read data ---------------------------------------------------------------

# notes: 
# - Pinterest (pinterest-20) and Movie Lense (ml-1m) data
# - user & item indexes are 0 based.
# - train.rating contains user/item/rating triplets (plus a timestamp)
# - test.negative contains a list of 100 negatives and one positive for each user
# - test.rating contains user/item/rating triplets (plus a timestamp) for 
#   each user's single rating in ml-1m.test.negative. 

movielense <- FALSE #set to F for pinterest data
if(movielense){
  file_prefix <- "ml-1m"  
}else{
  file_prefix <- "pinterest-20"   
}

base_name <- str_c("https://github.com/hexiangnan/neural_collaborative_filtering/raw/master/Data/", file_prefix)

url <- str_c(base_name, ".train.rating")
train_rating <- read_tsv(pins::pin(url), 
                         col_names = c("user","item", "rating", "timestamp")) 

url <-  str_c(base_name, ".test.negative")
test_data <- pins::pin(url) 
#test_rating   <- read_tsv(test_data[str_detect(test_data, "rating")], 
#                          col_names = c("user","item", "rating", "timestamp"))
test_negative <- read_tsv(test_data[str_detect(test_data, "negative")], 
                          col_names = FALSE) 

#See pins issue: https://github.com/rstudio/pins/issues/271
#url <- "https://github.com/hexiangnan/neural_collaborative_filtering/raw/master/Data/ml-1m.test.negative"
#test_negative <- read_tsv(pins::pin(url), 
#                          col_names = FALSE) 


# Variable definitions ----------------------------------------------------

num_users <- max(train_rating$user) + 1
num_items <- max(train_rating$item) + 1
neg_pos_ratio_train <- 4 # Ratio of negative training samples to positive to select for training. NCF authors used 4.


# Data wrangling ----------------------------------------------------------

# Test set

test <- test_negative %>% 
  tidyr::extract(X1, into = c("user", "pos_item"), "([[:alnum:]]+),([[:alnum:]]+)", convert = TRUE) %>%
  pivot_longer(cols = pos_item:X100, names_to = "label", values_to = "item") %>%
  mutate(label = as.integer(!str_detect(label,"X")))

# Get number of training ratings per user (will need for sampling negatives)
num_ratings_per_user <- train_rating %>% group_by(user) %>% count() %>% ungroup()

```

## R version of code in question

Note that I may possibly be able to do the following using vectors/purrr/furrr.

I tried arrow, but they don't have anti_join implemented yet.

```{r}
# Sample negatives (those movies that were not rated for each user) to use for training 
tictoc::tic()
train_negative <- 
  lazy_dt(data.frame(user = rep(0:(num_users-1), each=num_items), 
                     item = 0:(num_items-1))) %>%   # start by listing all user/item pairs 
  anti_join(bind_rows(train_rating, test))  %>%     # remove user/item pairs that are in test and positive training sets
  as_tibble() %>%     # because dtdplyr doesn't have nest functionality
  group_by(user) %>%  
  nest() %>%  
  lazy_dt() %>%
  #tidyfast::dt_nest(user) %>%  #didn't work for follow-on processes
  inner_join(num_ratings_per_user) %>%
  mutate(subsamp = map2(data, n*neg_pos_ratio_train, ~slice_sample(.x, n=.y))) %>% 
  select(user, subsamp) %>%
  #tidyfast::dt_unnest() %>%  
  as_tibble() %>%
  unnest(cols = c(subsamp))
tictoc::toc() #147 sec using dtplyr

```

The following R code is estimated to take 56 hours:

```{r}
### Test code
# library(arrow) # Tried arrow, but it doesn't have anti_join implemented yet.
tic()
exclude <- bind_rows(train_positive, 
                     validation, 
                     test_positive, 
                     train_negative, 
                     test_negative)
tic()
result <- list()
for(i in 1:30){
  result[[i]] <- 
    new_book_id_df %>%
    anti_join(
      filter(exclude, user_id == df[i, "user_id"][[1]])
    ) %>%
    slice_sample(n = df[i, "num_implicit_neg_2sample_4test"][[1]])
  print(i)
}
toc()
```

The following is estimated to take 61 hours

```{r}
tic()
df %>% 
  select(user_id, num_implicit_neg_2sample_4test) %>%
  mutate(data2samp = map(user_id, ~  anti_join(new_book_id_df, filter(exclude, user_id == .), by = "book_id") ),
         implicit_neg_samples_test = map2(num_implicit_neg_2sample_4test, data2samp, ~ slice_sample(.y, n = .x))) %>%
  select(-data2samp)
toc()
```

Tried furrr to speed up code above, but it produced error b/c data that needs to be "exported" is too large. Need to modify option future.globals.maxSize

```{r}
library(furrr)
plan(multisession, workers = 4)
tic()
df[1:3,] %>% 
  select(user_id, num_implicit_neg_2sample_4test) %>%
  mutate(data2samp = future_map(user_id, ~  anti_join(new_book_id_df, filter(exclude, user_id == .), by = "book_id") ),
         implicit_neg_samples_test = future_map2(num_implicit_neg_2sample_4test, data2samp, ~ slice_sample(.y, n = .x) ) ) %>%
  select(-data2samp)
toc()
```


The following R implementation was *significantly* slower than the dplyr version above. Might possibly try something with vectors and lapply/purrr.

```{r}
# TODO: Implement the following in purrr/furrr. For-loop takes 230 seconds compared to method above, which takes 20 seconds (but is memory intensive.)
#tictoc::tic()
#train_negative <- list(NA, dim = num_users)
#for(u in 0:(num_users-1)){
#  x <- filter(test, user == u) 
#  y <- filter(train_rating, user == u) 
#  cnt <- filter(num_ratings_per_user, user == u) 
#  sample_set <- setdiff(0:(num_items-1), c(x$item, y$item))
#  user_negative_items <- sample(sample_set, size = min(neg_pos_ratio_train * cnt$n, length(sample_set)))
#  train_negative[[u+1]] <- tibble(user = rep(u, length(user_negative_items)), item =  user_negative_items)
#}
#train_negative <- bind_rows(train_negative)
#tictoc::toc() #238 seconds for ml dataset.
```


## Python version

```{python}

import numpy as np
import pandas as pd

# Data needed:
train = r.train_rating # positive ratings in the training set
test  = r.test         # ratings in the test set
num_ratings_per_user = r.num_ratings_per_user  # specifies number of positive samples that each user has in the training set
neg_pos_ratio_train  = r.neg_pos_ratio_train   # An integer specifying the ratio of negative to positive examples (the paper uses 4)

# group the pandas df by user
gpd = train.groupby("user")

# iterate to create positive lists
user_positive = [ (user, np.array(pd.DataFrame(df_small).item, dtype=int)) for (user, df_small) in gpd]

# Goal: Sample implicit negatives (user/item pairs) to be added to the training set. Exclude pairs already in test and train sets. 

def sample_implicit_negatives(num_items, n, excludes=[] ):
    item_indices = np.arange(0,int(num_items))
    return np.random.choice( np.setdiff1d(item_indices, excludes), size=int(n) )

#import time
#t_0 = time.time()

train_negative = [ (u, sample_implicit_negatives(r.num_items, len(pos_items)*r.neg_pos_ratio_train, excludes=pos_items)) for (u, pos_items) in user_positive ]

#t_1 = time.time()
#print( f"num seconds is {t_1-t_0}") # 50 seconds
```


